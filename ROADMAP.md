# ğŸ§­ Development Roadmap: Abstract Network for AtlasEnv

> Modular architecture for decentralized communication, focusing on pluggability, distributed validation, and peer control.

---

## âœ… Phase 1 â€“ Core Structure

### ğŸ“Œ Goal

Create a generic `Network` interface to support multiple implementations (in-memory, TCP, libp2p, etc.).

### ğŸ“‹ Tasks

- [x] Define `ClusterMessage` enum with:
  - Signed proposal
  - Signed vote
- [x] Define `NetworkError` enum
- [x] Create `trait Network` with:
  - `send_to`
  - `broadcast`
  - `connected_peers`
  - `set_message_handler`
- [x] Make the **network injectable** (via trait object `Arc<dyn Network>`)

---

## ğŸ§ª Phase 2 â€“ Simulated Implementation (InMemoryNetwork)

### ğŸ“Œ Goal

Provide an in-memory network for simulation and local testing.

### ğŸ“‹ Tasks

- [x] Create `InMemoryNetwork` struct
- [ ] Manage `peers: HashMap<NodeId, Sender<ClusterMessage>>`
- [x] Implement `send_to` and `broadcast` using `tokio::sync::mpsc` channels
- [x] Implement `set_message_handler` with `Fn(ClusterMessage)` callback

---

## ğŸ”‘ Phase 3 â€“ Decoupled Authentication

### ğŸ“Œ Goal

Allow swapping the message authentication/signature mechanism.

### ğŸ“‹ Tasks

- [x] Make **authentication system injectable** (e.g. `trait Authenticator`)
- [x] Separate `sign()` and `verify()` for proposals and votes
- [x] Support multiple signature schemes (ed25519, secp256k1, etc.)

---

## ğŸ” Phase 4 â€“ Callback Integration into AtlasEnv

### ğŸ“Œ Goal

Allow `AtlasEnv` to react to received consensus messages.

### ğŸ“‹ Tasks

- [x] Add channel or closure in `NetworkAdapter` for `on_message(msg)`
- [x] Integrate `set_message_handler` with `ConsensusEngine` and `Storage`
- [x] Allow Atlas to decide the message's destination (vote, ignore, etc.)

---

## ğŸŒ± Phase 5 â€“ Root Proposals (`parent = None`)

### ğŸ“Œ Goal

Enable proposals without a parent (root proposals), allowing graph bootstrapping.

### ğŸ“‹ Tasks

- [x] Update `Proposal` model to support `parent: Option<String>`
- [x] Validate root proposals as consensus starting points
- [ ] Create test for consensus bootstrapping without ancestry

---

## ğŸŒ Phase 6 â€“ Peer Management

### ğŸ“Œ Goal

Enable each node to dynamically maintain ~30 peers.

### ğŸ“‹ Tasks

- [x] Add `PeerManager` module
- [x] Implement peer discovery by propagation
- [x] Implement removal of slow peers
- [x] Enforce peer limit and overflow queue

---

## ğŸ—³ï¸ Phase 7 â€“ Asynchronous Consensus with Quorum

### ğŸ“Œ Goal

Validate proposals asynchronously with a minimum quorum (e.g. 20 votes).

### ğŸ“‹ Tasks

- [ ] Node A sends to its 30 peers
- [ ] A stores votes until reaching quorum
- [ ] After quorum, proposal is published
- [ ] Expired messages (by timestamp) are ignored

---

## ğŸ”Œ Phase 8 â€“ Real Network Adapters

### ğŸ“Œ Goal

Support multiple real-world network adapters.

### ğŸ“‹ Tasks

- [ ] `WebSocketAdapter` with `tokio-tungstenite`
- [ ] `Libp2pAdapter` with automatic peer discovery
- [ ] Add pluggability via `AtlasEnv::new(..., Box<dyn Network>)`

---

## ğŸ§¹ Phase 9 â€“ Optimizations & Resilience

### ğŸ“Œ Goal

Make the network robust and secure against byzantine failures.

### ğŸ“‹ Tasks

- [x] Signature verification (using injected Auth)
- [ ] Message deduplication
- [ ] Network logging and metrics
- [ ] Support for node re-entry after disconnection

---

## ğŸ§© Phase 10 â€“ Extras

- [ ] Optional message compression
- [ ] Local persistence of peer list
- [ ] Future support for WebAssembly and WebRTC

---

# AtlasDB (Fiducial) â€” Checklist de ImplementaÃ§Ã£o

## P0 â€” FundaÃ§Ã£o e SeguranÃ§a do NÃºcleo

- [ ] **Erros tipados (thiserror) unificados**
  - Criar `AtlasError` + `type Result<T> = std::result::Result<T, AtlasError>;`
  - Migrar `Result<_, String>` â†’ `Result<_, AtlasError>` em `cluster/*`, `jobs/*`, `runtime/*`, `env/*`.
- [ ] **PolÃ­tica de quÃ³rum**
  - Implementar `QuorumPolicy { fraction â‰¥ 0.5, min_voters }` e usar em agregaÃ§Ã£o de votos/acks.
  - Parametrizar via config.
- [ ] **Observabilidade mÃ­nima**
  - Trocar `println!` â†’ `tracing::{info,warn,error,debug}`.
  - `main.rs`: configurar `tracing_subscriber` com `EnvFilter` (`RUST_LOG=atlas=info,tokio=warn`).
  - Usar `#[instrument]` nos handlers gRPC e hot paths (bus worker, broadcast/handle).

---

## P1 â€” I/O ConfiÃ¡vel e ReprodutÃ­vel

- [ ] **PersistÃªncia (KV mÃ­nima)**
  - Backend (ex.: `sled`): `put/get`.
  - Persistir peers, audit de mensagens (proposals/votes), e metadados essenciais.
  - Recarregar no boot (estado base do cluster).
- [ ] **mTLS na camada gRPC**
  - Server/Client com `Identity` + `client_ca_root`.
  - Configurar paths no `config.json`.
  - (Opcional) mapear identidade do peer a `NodeId`.

---

## P2 â€” Consenso Completo (entrada â†’ decisÃ£o â†’ saÃ­da)

- [ ] **Mempool dentro do consenso (entrada)**
  - Trait `Mempool` (add/select/mark_included).
  - Integrar no `ConsensusEngine`/proposer para montar propostas/blocos.
- [ ] **Ledger dentro do consenso (saÃ­da)**
  - Trait `Ledger` (apply_block/apply_decision, replay).
  - Ao atingir quÃ³rum: aplicar no ledger, registrar no KV, limpar mempool.
  - Garantir idempotÃªncia (replay apÃ³s restart).
- [ ] **Fechamento de consenso â†’ commit**
  - `HandleVote/Proposal`: quando `grants >= quorum_required`, fechar decisÃ£o e acionar `ledger.apply_*`.

---

## P3 â€” Runtime & Jobs Robustos

- [ ] **Runtime/Builder consolidado (sem anyhow)**
  - `build_runtime()` retorna `Result<_, AtlasError>`.
  - `CommandBus::new(arc.clone(), ..)` (sem `&`), timeout por `cmd.timeout()`.
  - Agendar `BroadcastHeartbeat` com jitter no `Scheduler`.
- [ ] **Melhorias no CommandBus/Scheduler**
  - Logs estruturados por `job_id`, `cmd`, `status`, `dur`.
  - (Opcional) Retry/backoff para `NoQuorum` no Bus ou Scheduler.

---

## P4 â€” ConfiguraÃ§Ã£o & ValidaÃ§Ã£o

- [ ] **Config completa**
  - `quorum_min_voters`, `quorum_fraction`.
  - `tls: { cert_path, key_path, ca_path }`.
  - `storage_path` (KV).
  - ValidaÃ§Ã£o: `fraction â‰¥ 0.5`, caminhos existentes.

---

## P5 â€” Telemetria (depois do bÃ¡sico)

- [ ] **MÃ©tricas**
  - Contadores: `heartbeats_sent/recv`, `jobs_completed/failed/timeout`, `votes_granted`, `quorum_required`, `mempool_size`.
  - (Opcional) `/metrics` Prometheus.

---

## SequÃªncia Sugerida

1. **P0** (Erros + QuÃ³rum + Logs)
2. **P1** (KV + mTLS)
3. **P2** (Mempool + Ledger + Commit Path)
4. **P3** (Runtime/Jobs refinado)
5. **P4** (Config final)
6. **P5** (MÃ©tricas)

---

# âœ… Checklist Fiducial vs PIX

## Core

- [ ] **Definir estados de transaÃ§Ã£o**
  - `accepted_optimistic` â†’ `finalized` â†’ `checkpointed`
  - (e opcional: `reverted`)
- [ ] **Implementar dois modos de confirmaÃ§Ã£o (M0/M1)**
  - M0: validaÃ§Ã£o local rÃ¡pida (optimistic)
  - M1: consenso com quorum (finality)
- [ ] **Limites de M0**
  - Valor mÃ¡ximo
  - FrequÃªncia por conta
  - Score/reputaÃ§Ã£o

---

## ExecuÃ§Ã£o / Performance

- [ ] **Paralelizar validaÃ§Ã£o** com Rayon
- [ ] **Buckets por conta** (hash % N) â†’ paralelismo determinÃ­stico
- [ ] **ExecuÃ§Ã£o paralela dentro do bloco**
- [ ] **Batching no WAL** (fsync por tamanho/tempo)
- [ ] **Batch verify de assinaturas** (quando suportado)

---

## Consenso / Cluster

- [ ] **Leader-per-shard com lease** (menos reeleiÃ§Ãµes)
- [ ] **Assinaturas agregadas (BLS ou similar)** para blocos/checkpoints
- [ ] **AppendEntries paralelos** por follower
- [ ] **Checkpoints periÃ³dicos** (root + sig agregada)

---

## Mempool / Network

- [ ] **Fila por conta** (um tx ativo por conta)
- [ ] **Anti-duplicata** (Bloom ou CRDT leve)
- [ ] **Hints de roteamento** â†’ manda direto ao lÃ­der do shard
- [ ] **Prioridade** (tamanho/fee ou custo computacional)

---

## Camadas de Escala

- [ ] **Aggregator (rollup simples)**: empacotar 100â€“1000 tx, publicar root
- [ ] **Canais/sessÃµes** (off-chain settlement)
- [ ] **Checkpoint opcional em L1 externo** (Ã¢ncora)

---

## Observabilidade

- [ ] **MÃ©tricas TPS** (optimistic/final)
- [ ] **LatÃªncia p50/p95** (optimistic/final)
- [ ] **% revertidas no M0**
- [ ] **Spans crÃ­ticos**: `validate_tx`, `exec_tx`, `wal_commit`, `append_entries`
- [ ] **Logs estruturados** (com node_id, term, index, req_id)

---

## Cliente / UX

- [ ] **Endpoints claros**
  - `POST /tx` â†’ retorna `{status: accepted_optimistic}`
  - `GET /tx/{id}` â†’ mostra estado atual
- [ ] **Tempo mÃ©dio de reversÃ£o (M0)** exposto na API
- [ ] **Mensagens de status amigÃ¡veis** pro usuÃ¡rio final
